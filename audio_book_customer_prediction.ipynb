{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwstEa15EwLl/YXoL5mBbB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cyril-19/Cyril-19/blob/main/audio_book_customer_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fvEElG1SBKUZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "raw_csv_data = np.loadtxt('Audiobooks_data.csv',delimiter=',')\n",
        "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
        "targets_all = raw_csv_data[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "gHjq-ao_BKUi"
      },
      "outputs": [],
      "source": [
        "num_one_targets = int(np.sum(targets_all))\n",
        "zero_targets_counter = 0\n",
        "indices_to_remove = []\n",
        "for i in range(targets_all.shape[0]):\n",
        "    if targets_all[i] == 0:\n",
        "        zero_targets_counter += 1\n",
        "        if zero_targets_counter > num_one_targets:\n",
        "            indices_to_remove.append(i)\n",
        "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)\n",
        "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZA0jMmrQBKUl"
      },
      "outputs": [],
      "source": [
        "\n",
        "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "YR8eoYquBKUo"
      },
      "outputs": [],
      "source": [
        "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
        "shuffled_targets = targets_equal_priors[shuffled_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UVp_9p8KBKUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f91f82-4d46-4b86-8f17-ac315014f7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1811.0 3579 0.50600726459905\n",
            "207.0 447 0.46308724832214765\n",
            "219.0 448 0.4888392857142857\n"
          ]
        }
      ],
      "source": [
        "\n",
        "samples_count = shuffled_inputs.shape[0]\n",
        "train_samples_count = int(0.8 * samples_count)\n",
        "validation_samples_count = int(0.1 * samples_count)\n",
        "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
        "train_inputs = shuffled_inputs[:train_samples_count]\n",
        "train_targets = shuffled_targets[:train_samples_count]\n",
        "\n",
        "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
        "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
        "\n",
        "\n",
        "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
        "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
        "\n",
        "\n",
        "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
        "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
        "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "cLfQKIfgBKUt"
      },
      "outputs": [],
      "source": [
        "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
        "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
        "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6-TSE3WmqBct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803f7d2f-a87c-4ed5-b979-00f8de5edf86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-12982d585254>:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_inputs = npz['inputs'].astype(np.float)\n",
            "<ipython-input-19-12982d585254>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_targets = npz['targets'].astype(np.int)\n",
            "<ipython-input-19-12982d585254>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
            "<ipython-input-19-12982d585254>:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
            "<ipython-input-19-12982d585254>:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
            "<ipython-input-19-12982d585254>:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n"
          ]
        }
      ],
      "source": [
        "npz = np.load('Audiobooks_data_train.npz')\n",
        "train_inputs = npz['inputs'].astype(np.float)\n",
        "train_targets = npz['targets'].astype(np.int)\n",
        "npz = np.load('Audiobooks_data_validation.npz')\n",
        "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
        "npz = np.load('Audiobooks_data_test.npz')\n",
        "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "VJgDIHnLGPvt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Gh5Zf5tmqBc0",
        "outputId": "c7b1dd15-7059-4dea-e9a7-2f485c369353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 1s 7ms/step - loss: 0.6150 - accuracy: 0.6482 - val_loss: 0.5103 - val_accuracy: 0.7136\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7499 - val_loss: 0.4372 - val_accuracy: 0.7696\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7809 - val_loss: 0.4012 - val_accuracy: 0.7673\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.7916 - val_loss: 0.3827 - val_accuracy: 0.7852\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.7991 - val_loss: 0.3729 - val_accuracy: 0.7942\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8005 - val_loss: 0.3677 - val_accuracy: 0.8143\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8117 - val_loss: 0.3660 - val_accuracy: 0.7964\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8069 - val_loss: 0.3603 - val_accuracy: 0.8031\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8134 - val_loss: 0.3615 - val_accuracy: 0.8031\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8125 - val_loss: 0.3584 - val_accuracy: 0.7987\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8139 - val_loss: 0.3569 - val_accuracy: 0.8166\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8187 - val_loss: 0.3618 - val_accuracy: 0.8009\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8148 - val_loss: 0.3533 - val_accuracy: 0.8054\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8178 - val_loss: 0.3536 - val_accuracy: 0.8188\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8148 - val_loss: 0.3529 - val_accuracy: 0.8277\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8195 - val_loss: 0.3433 - val_accuracy: 0.8098\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8153 - val_loss: 0.3680 - val_accuracy: 0.8031\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8206 - val_loss: 0.3472 - val_accuracy: 0.7987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa871d85730>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "input_size = 10\n",
        "output_size = 2\n",
        "hidden_layer_size = 50\n",
        "    \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "batch_size = 100\n",
        "max_epochs = 100\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "\n",
        "model.fit(train_inputs, \n",
        "          train_targets,\n",
        "          batch_size=batch_size,\n",
        "          epochs=max_epochs, \n",
        "          callbacks=[early_stopping],\n",
        "          validation_data=(validation_inputs, validation_targets), \n",
        "          )  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MWQSIESjqBc-",
        "outputId": "071aa4a8-ac1d-428a-e5e4-acbd0813be25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8237\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZjIdAVprqBdA",
        "outputId": "5a0e3a85-2cfc-4504-ce6b-94555ae067a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test loss: 0.32. Test accuracy: 82.37%\n"
          ]
        }
      ],
      "source": [
        "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ]
    }
  ]
}